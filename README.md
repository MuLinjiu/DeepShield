# DeepShield - Network Traffic Security Classifier

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

åŸºäºLoRAï¼ˆLow-Rank Adaptationï¼‰æŠ€æœ¯çš„ç½‘ç»œæµé‡å®‰å…¨åˆ†ç±»å™¨ï¼Œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç½‘ç»œæ”»å‡»æ£€æµ‹å’Œåˆ†ç±»ã€‚

## âœ¨ ç‰¹æ€§

- ğŸ¯ **ç²¾ç¡®åˆ†ç±»**ï¼šæ”¯æŒå¤šç§ç½‘ç»œæ”»å‡»ç±»å‹è¯†åˆ«ï¼ˆWeb Attackã€Brute Forceã€Infiltrationç­‰ï¼‰
- ğŸ§  **å¯è§£é‡Šæ€§**ï¼šç”Ÿæˆåˆ†ç±»åŸå› è¯´æ˜
- ğŸ’¡ **å‚æ•°é«˜æ•ˆ**ï¼šä½¿ç”¨LoRAæŠ€æœ¯ï¼Œåªè®­ç»ƒå°‘é‡å‚æ•°
- ğŸš€ **çµæ´»æ¨¡å‹**ï¼šæ”¯æŒLlama-3.1ã€Qwen2.5/3ç­‰å¤šç§åŸºåº§æ¨¡å‹
- ğŸ“Š **ä¸°å¯ŒæŒ‡æ ‡**ï¼šè¯¦ç»†çš„per-class precision/recall/f1è¯„ä¼°

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®HuggingFace Tokenï¼ˆå¯é€‰ï¼‰

å¯¹äºå…¬å¼€æ¨¡å‹ï¼ˆå¦‚Llama-3.1ï¼‰ï¼Œä¸éœ€è¦tokenã€‚å¦‚æœä½¿ç”¨gatedæ¨¡å‹ï¼Œéœ€è¦è®¾ç½®tokenï¼š

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„token
# HF_TOKEN=hf_xxxxxxxxxx

# æˆ–ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡
export HF_TOKEN=your_token_here
```

### 3. å‡†å¤‡æ•°æ®

åˆ›å»ºå¹³è¡¡è®­ç»ƒé›†ï¼ˆä»åŸå§‹æ•°æ®é›†é‡‡æ ·20Kæ ·æœ¬ï¼‰ï¼š

```bash
python3 create_12h_training_set.py \
  --input_train data/processed/llm_input_enriched_train.jsonl \
  --input_val data/processed/llm_input_enriched_val.jsonl \
  --output_train data/processed/train_12h.jsonl \
  --output_val data/processed/val_12h.jsonl
```

åˆ›å»ºè‡ªç„¶åˆ†å¸ƒæµ‹è¯•é›†ï¼ˆ10Kæ ·æœ¬ï¼Œä¿æŒåŸå§‹99% BENIGNæ¯”ä¾‹ï¼‰ï¼š

```bash
python3 create_natural_test_set.py
```

### 4. è®­ç»ƒæ¨¡å‹

```bash
CUDA_VISIBLE_DEVICES=0 python3 train_lora_netflow_refined.py \
  --train_path data/processed/train_12h.jsonl \
  --val_path data/processed/val_12h.jsonl \
  --base_model meta-llama/Llama-3.1-8B-Instruct \
  --out_dir lora-llama31-12h \
  --epochs 3 \
  --max_len 1536 \
  --per_device_bs 2 \
  --grad_accum 8 \
  --load_in_4bit \
  --bf16
```

### 5. è¯„ä¼°æ¨¡å‹

å¹³è¡¡æµ‹è¯•é›†ï¼ˆ100æ ·æœ¬ï¼‰ï¼š
```bash
CUDA_VISIBLE_DEVICES=0 python3 train_lora_netflow_refined.py \
  --eval_path data/processed/llm_input_enriched_test_sample100.jsonl \
  --adapter lora-llama31-12h/checkpoint-800 \
  --base_model meta-llama/Llama-3.1-8B-Instruct \
  --mode eval
```

è‡ªç„¶åˆ†å¸ƒæµ‹è¯•é›†ï¼ˆ10Kæ ·æœ¬ï¼Œ~99% BENIGNï¼‰ï¼š
```bash
CUDA_VISIBLE_DEVICES=0 python3 train_lora_netflow_refined.py \
  --eval_path data/processed/llm_input_enriched_test_natural10k.jsonl \
  --adapter lora-llama31-12h/checkpoint-800 \
  --base_model meta-llama/Llama-3.1-8B-Instruct \
  --mode eval
```

è¯„ä¼°Base Modelï¼ˆæ— LoRAï¼‰ï¼š
```bash
CUDA_VISIBLE_DEVICES=0 python3 train_lora_netflow_refined.py \
  --eval_path data/processed/llm_input_enriched_test_sample100.jsonl \
  --base_model meta-llama/Llama-3.1-8B-Instruct \
  --mode eval
```

---

## ğŸ“Š æ•°æ®æ ¼å¼

### è¾“å…¥æ•°æ®æ ¼å¼ï¼ˆJSONLï¼‰

```json
{
  "flow_id": 1,
  "tuple5": ["192.168.1.1", "10.0.0.1", 45123, 80, 6],
  "window": [1234567890.0, 1234567895.0],
  "features": {
    "packet_count": 150,
    "byte_count": 75000,
    "flow_dur_ms": 5000.0,
    "tcp_syn_ratio": 0.02,
    "payload_entropy": 6.5,
    ...
  },
  "enriched": {
    "protocols": ["HTTP", "TCP"]
  },
  "label": "Web Attack - XSS"
}
```

### æ¨¡å‹è¾“å‡ºæ ¼å¼

```json
{
  "label": "Web Attack - XSS",
  "explanation": "HTTP traffic on port 80 with high packet count (150 packets) and large payload (75KB) showing high ASCII ratio (0.85) indicating text-based content"
}
```

---

## ğŸ® æ”¯æŒçš„æ¨¡å‹

### Llamaç³»åˆ—
- `meta-llama/Llama-3.1-8B-Instruct` ï¼ˆæ¨èï¼‰
- `meta-llama/Llama-2-7b-hf`

### Qwenç³»åˆ—
- `Qwen/Qwen3-8B-Instruct` ï¼ˆæœ€æ–°ï¼‰
- `Qwen/Qwen2.5-7B-Instruct`

### å…¶ä»–
- `mistralai/Mistral-7B-Instruct-v0.2`

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
DeepShield/
â”œâ”€â”€ train_lora_netflow_refined.py      # ä¸»è®­ç»ƒ/è¯„ä¼°è„šæœ¬
â”œâ”€â”€ create_12h_training_set.py         # åˆ›å»ºå¹³è¡¡è®­ç»ƒé›†
â”œâ”€â”€ create_natural_test_set.py         # åˆ›å»ºè‡ªç„¶åˆ†å¸ƒæµ‹è¯•é›†
â”œâ”€â”€ requirements.txt                    # Pythonä¾èµ–
â”œâ”€â”€ .env.example                        # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .gitignore                          # Gitå¿½ç•¥é…ç½®
â””â”€â”€ data/processed/                     # æ•°æ®ç›®å½•
    â”œâ”€â”€ train_12h.jsonl                 # å¹³è¡¡è®­ç»ƒé›†ï¼ˆ20Kï¼‰
    â”œâ”€â”€ val_12h.jsonl                   # éªŒè¯é›†ï¼ˆ2Kï¼‰
    â”œâ”€â”€ llm_input_enriched_test_sample100.jsonl  # æµ‹è¯•é›†ï¼ˆ100ï¼‰
    â””â”€â”€ llm_input_enriched_test_natural10k.jsonl # è‡ªç„¶åˆ†å¸ƒæµ‹è¯•é›†ï¼ˆ10Kï¼‰
```

---

## âš™ï¸ è®­ç»ƒå‚æ•°è¯´æ˜

### åŸºç¡€å‚æ•°
- `--base_model`: åŸºåº§æ¨¡å‹åç§°
- `--train_path`: è®­ç»ƒæ•°æ®è·¯å¾„
- `--val_path`: éªŒè¯æ•°æ®è·¯å¾„
- `--out_dir`: è¾“å‡ºç›®å½•
- `--adapter`: LoRA adapterè·¯å¾„ï¼ˆevalæ—¶ä½¿ç”¨ï¼‰

### LoRAé…ç½®
- `--r`: LoRA rankï¼ˆé»˜è®¤16ï¼‰
- `--alpha`: LoRA alphaï¼ˆé»˜è®¤32ï¼‰
- `--dropout`: LoRA dropoutï¼ˆé»˜è®¤0.05ï¼‰

### è®­ç»ƒé…ç½®
- `--epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤3ï¼‰
- `--lr`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤2e-4ï¼‰
- `--per_device_bs`: æ¯è®¾å¤‡batch sizeï¼ˆé»˜è®¤1ï¼‰
- `--grad_accum`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆé»˜è®¤16ï¼‰
- `--max_len`: æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤4096ï¼‰

### å®éªŒæ€§å‚æ•°
- `--remove_eos_from_training`: å»æ‰è®­ç»ƒåºåˆ—çš„EOS tokenï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆexplanation
- `--disable_explanation_fallback`: ç¦ç”¨hard-coded explanationç”Ÿæˆfallback

---

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

è¯„ä¼°æ—¶ä¼šè¾“å‡ºï¼š

### æ€»ä½“æŒ‡æ ‡
- Accuracy
- Macro Precision/Recall/F1
- Weighted Precision/Recall/F1

### Per-ClassæŒ‡æ ‡
- æ¯ä¸ªç±»åˆ«çš„Precisionã€Recallã€F1ã€Support

ç¤ºä¾‹è¾“å‡ºï¼š
```
============================================================
Overall Metrics:
============================================================
Accuracy:          0.9850
Macro Precision:   0.8234
Macro Recall:      0.7891
Macro F1:          0.8058
Weighted Precision: 0.9823
Weighted Recall:    0.9850
Weighted F1:        0.9836
Total Samples:      10000

============================================================
Per-Class Metrics:
============================================================
Class                                Precision     Recall         F1    Support
--------------------------------------------------------------------------------
BENIGN                                  0.9900     0.9990     0.9945       9911
Web Attack - Brute Force                0.7500     0.7500     0.7500         37
Web Attack - XSS                        0.8333     0.8333     0.8333         27
...
```

---

## ğŸ› ï¸ æŠ€æœ¯ç»†èŠ‚

### è®­ç»ƒç­–ç•¥

è®­ç»ƒæ•°æ®æ ¼å¼ï¼š
```json
{"label": "Web Attack - XSS", "explanation": "
```

- Completionåœ¨å¼•å·æœªé—­åˆå¤„ç»“æŸ
- ä¸åŒ…å«EOS tokenï¼ˆä½¿ç”¨ `--remove_eos_from_training`ï¼‰
- é¼“åŠ±æ¨¡å‹åœ¨evalæ—¶ç»§ç»­ç”Ÿæˆexplanation

### LoRAé…ç½®
- Target modules: `q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj`
- 4-bité‡åŒ–ï¼ˆ`load_in_4bit`ï¼‰
- BF16æ··åˆç²¾åº¦è®­ç»ƒ

### å­¦ä¹ ç‡è°ƒåº¦
- Scheduler: Cosine with warmup
- Warmup steps: 100
- Learning rate: 2e-4

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. HuggingFace Tokené”™è¯¯
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export HF_TOKEN=your_token_here

# æˆ–ä½¿ç”¨.envæ–‡ä»¶
cp .env.example .env
# ç¼–è¾‘.envå¡«å…¥token
```

### 2. CUDA Out of Memory
- å‡å°‘ `--per_device_bs`ï¼ˆå°è¯•1ï¼‰
- å¢åŠ  `--grad_accum`ï¼ˆå°è¯•16æˆ–32ï¼‰
- å‡å°‘ `--max_len`ï¼ˆå°è¯•1024æˆ–512ï¼‰
- ä½¿ç”¨4-bité‡åŒ–ï¼ˆ`--load_in_4bit`ï¼‰

### 3. è®­ç»ƒå¤ªæ…¢
- å¢åŠ  `--per_device_bs`ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
- å‡å°‘ `--grad_accum`
- ä½¿ç”¨æ›´å°‘æ•°æ®æˆ–æ›´å°‘epochs

---

## ğŸ“„ License

MIT License

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

---

## âš ï¸ å…è´£å£°æ˜

æœ¬å·¥å…·ä»…ç”¨äºå®‰å…¨ç ”ç©¶å’Œæ•™è‚²ç›®çš„ã€‚ä½¿ç”¨è€…éœ€éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„ã€‚
